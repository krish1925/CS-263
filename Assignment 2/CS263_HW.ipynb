{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAW1pKvx5PTz"
      },
      "source": [
        "# CS 263 HW Notebook\n",
        "\n",
        "This notebook comprises of python scripts to extract chatgpt output and instructions for checking the format of your files for the submission of the homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4CBD9F0MLU9"
      },
      "source": [
        "## Extract ChatGPT Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "_ST3-00z8gKo"
      },
      "outputs": [],
      "source": [
        "\n",
        "def argument_extractor(chatgpt_output, argument_roles=None):\n",
        "    \"\"\"\n",
        "    Extract arguments corresponding to the argument roles from the chatgpt_output.\n",
        "    If argument roles are provided, this will extract only those arguments.\n",
        "    Else it will extract all possible arguments from the output.\n",
        "    \"\"\"\n",
        "    print(\"Inside argument extractor\")\n",
        "    print(\"chat outputs: \" ,chatgpt_output)\n",
        "    print(\"Argument roles: \", argument_roles)\n",
        "    arguments = {}\n",
        "    print(argument_roles)\n",
        "    if argument_roles is not None:\n",
        "        for role in argument_roles:\n",
        "            pattern = rf\"\\b{role}:\\s*([^\\n]+)\"\n",
        "            match = re.search(pattern, chatgpt_output, re.IGNORECASE)\n",
        "            if match:\n",
        "                arguments[role] = match.group(1).strip()\n",
        "            else:\n",
        "                arguments[role] = None\n",
        "    return arguments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PrgnulpMPCP"
      },
      "source": [
        "## File-check for formatting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "wViu0qpq5LHp"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "EVENT_NAMES = [\"infect\", \"spread\", \"symptom\", \"cure\", \"prevent\", \"control\", \"death\"]\n",
        "ONTOLOGY_FIELD_NAMES = {\"event_name\": str, \"argument_role\": str, \"role_description\": str, \"example_sentence\": str}\n",
        "DATA_ANNOTATION_FIELD_NAMES = {\"input_text\": str, \"event_name\": str, \"event_trigger\": str, \"arguments\": dict}\n",
        "PREDICTION_FIELD_NAMES = {\"input_text\": str, \"prompt\": str, \"output_text\": str, \"extracted_arguments\": dict}\n",
        "BREAKGPT_FIELD_NAMES = {\"input_text\": str, \"event_name\": str, \"event_trigger\": str, \"prompt\": str, \"output_text\": str, \"extracted_arguments\": dict, \"expected_arguments\": dict}\n",
        "\n",
        "def ontology_check(filename):\n",
        "  data = None\n",
        "  with open(filename, 'r') as f:\n",
        "    try:\n",
        "      data = json.load(f)\n",
        "    except:\n",
        "      print (\"ERROR: File is not a json file. Use json.dump to create your file\")\n",
        "      return\n",
        "\n",
        "  for i, dt in enumerate(data):\n",
        "    for field_name in dt.keys():\n",
        "      if field_name not in ONTOLOGY_FIELD_NAMES:\n",
        "        print (\"ERROR: Line %d: field name %s is incorrect. It should be within %s\" % (i+1, field_name, str(ONTOLOGY_FIELD_NAMES.keys())))\n",
        "        return\n",
        "\n",
        "    if dt[\"event_name\"] not in EVENT_NAMES:\n",
        "      print (\"ERROR: line %d has unknown event name %s. Please check.\" % (i+1, dt[\"event_name\"]))\n",
        "      return\n",
        "\n",
        "  print (\"PASSED: The format of the file %s looks correct!\" % filename)\n",
        "  return\n",
        "\n",
        "def json_check(filename, required_field_names, is_logs=0):\n",
        "  data = None\n",
        "  with open(filename, 'r') as f:\n",
        "    try:\n",
        "      data = json.load(f)\n",
        "    except:\n",
        "      print (\"ERROR: File is not a json file. Use json.dump to create your file\")\n",
        "      return\n",
        "\n",
        "  for i, dt in enumerate(data):\n",
        "    for field_name in dt.keys():\n",
        "      if field_name not in required_field_names.keys():\n",
        "        print (\"ERROR: Line %d: field name %s is incorrect. It should be within %s\" % (i+1, field_name, str(required_field_names.keys())))\n",
        "        return\n",
        "\n",
        "    for var, typ in required_field_names.items():\n",
        "      if not isinstance(dt[var], typ):\n",
        "        print (\"ERROR: Line %d: dt['%s'] is not a %s\" % (i+1, var, str(typ)))\n",
        "        return\n",
        "\n",
        "    if \"arguments\" in required_field_names and \"input_text\" in required_field_names:\n",
        "      for role, arg in dt[\"arguments\"].items():\n",
        "        if isinstance(arg, str) and arg not in dt[\"input_text\"]:\n",
        "          print (\"ERROR: Line %d: argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, arg))\n",
        "          return\n",
        "        elif isinstance(arg, list):\n",
        "          for a in arg:\n",
        "            assert isinstance(a, str)\n",
        "            if a not in dt[\"input_text\"]:\n",
        "              print (\"ERROR: Line %d: argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, a))\n",
        "              return\n",
        "\n",
        "    if \"expected_arguments\" in required_field_names and \"input_text\" in required_field_names:\n",
        "      for role, arg in dt[\"expected_arguments\"].items():\n",
        "        if isinstance(arg, str) and arg not in dt[\"input_text\"]:\n",
        "          print (\"ERROR: Line %d: expected argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, arg))\n",
        "          return\n",
        "        elif isinstance(arg, list):\n",
        "          for a in arg:\n",
        "            assert isinstance(a, str)\n",
        "            if a not in dt[\"input_text\"]:\n",
        "              print (\"ERROR: Line %d: argument '%s' not in the input text. Make sure your argument is in the input text\" % (i+1, a))\n",
        "              return\n",
        "\n",
        "    if \"extracted_arguments\" in required_field_names and \"output_text\" in required_field_names and not is_logs:\n",
        "      if argument_extractor(dt[\"output_text\"]) != dt[\"extracted_arguments\"]:\n",
        "        print (\"ERROR: Line %d: extracted arguments is inconsistent with chatgpt output based on script\" % (i+1))\n",
        "        print(\"Expected arguments: \", argument_extractor(dt[\"output_text\"]))\n",
        "        print(\"Extracted arguments: \", dt[\"extracted_arguments\"])\n",
        "        return\n",
        "\n",
        "  print (\"PASSED: The format of the file %s looks correct!\" % filename)\n",
        "  return\n",
        "\n",
        "def check_all_file_format():\n",
        "  ontology_check(\"ontology.json\")\n",
        "  json_check(\"in_context-annotated.json\", DATA_ANNOTATION_FIELD_NAMES)\n",
        "  json_check(\"eval_data-annotated.json\", DATA_ANNOTATION_FIELD_NAMES)\n",
        "  json_check(\"logs.json\", PREDICTION_FIELD_NAMES, is_logs=1)\n",
        "  json_check(\"break-gpt.json\", BREAKGPT_FIELD_NAMES)\n",
        "  json_check(\"pred.json\", PREDICTION_FIELD_NAMES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "pzkg0WjUgaPo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PASSED: The format of the file ontology.json looks correct!\n",
            "PASSED: The format of the file in_context-annotated.json looks correct!\n",
            "PASSED: The format of the file eval_data-annotated.json looks correct!\n",
            "PASSED: The format of the file logs.json looks correct!\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "argument_extractor() missing 1 required positional argument: 'argument_roles'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[151], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcheck_all_file_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[150], line 90\u001b[0m, in \u001b[0;36mcheck_all_file_format\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m json_check(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_data-annotated.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, DATA_ANNOTATION_FIELD_NAMES)\n\u001b[1;32m     89\u001b[0m json_check(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, PREDICTION_FIELD_NAMES, is_logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[43mjson_check\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbreak-gpt.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBREAKGPT_FIELD_NAMES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m json_check(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, PREDICTION_FIELD_NAMES)\n",
            "Cell \u001b[0;32mIn[150], line 76\u001b[0m, in \u001b[0;36mjson_check\u001b[0;34m(filename, required_field_names, is_logs)\u001b[0m\n\u001b[1;32m     73\u001b[0m           \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted_arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m required_field_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m required_field_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_logs:\n\u001b[0;32m---> 76\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43margument_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m dt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextracted_arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: Line \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m: extracted arguments is inconsistent with chatgpt output based on script\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected arguments: \u001b[39m\u001b[38;5;124m\"\u001b[39m, argument_extractor(dt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
            "\u001b[0;31mTypeError\u001b[0m: argument_extractor() missing 1 required positional argument: 'argument_roles'"
          ]
        }
      ],
      "source": [
        "check_all_file_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZYoK3rWyVQF4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "api_key = \"insert-key-here\"\n",
        "openai.api_key = api_key\n",
        "client = OpenAI(api_key = api_key)\n",
        "\n",
        "def sentiment_analysis(prompt):\n",
        "    response = client.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",  # Use an appropriate model for sentiment analysis\n",
        "        prompt=f\"Analyze the sentiment of the following text and respond with only one word: positive, neutral, or negative.\\n\\nText: {prompt}\\nSentiment:\",\n",
        "        temperature=0,  # Set temperature to 0 for deterministic output\n",
        "        max_tokens=1,   # Only need one token for the sentiment word\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "# Example usage:\n",
        "text = \"I love this product, it works great!\"\n",
        "result = sentiment_analysis(text)\n",
        "print(result)  # Should print \"positive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_ontology(file_name):\n",
        "    \"\"\"\n",
        "    Load the ontology from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        ontology = json.load(f)\n",
        "    return ontology\n",
        "\n",
        "def merge_example_sentences(event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Merge example sentences from the ontology with the input example sentences.\n",
        "    \"\"\"\n",
        "    for role in argument_roles:\n",
        "        for entry in ontology:\n",
        "            if entry[\"event_name\"] == event_name and entry[\"argument_role\"] == role:\n",
        "                ontology_examples = entry.get(\"example_sentence\", [])\n",
        "                if role in example_sentences:\n",
        "                    example_sentences[role].extend(ontology_examples)\n",
        "                else:\n",
        "                    example_sentences[role] = ontology_examples\n",
        "    return example_sentences\n",
        "\n",
        "def generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def call_chatgpt(prompt):\n",
        "    \"\"\"\n",
        "    Call ChatGPT API with the generated prompt and return the response.\n",
        "    \"\"\"\n",
        "    response = openai.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def argument_extractor(chatgpt_output, argument_roles=None):\n",
        "    \"\"\"\n",
        "    Extract arguments corresponding to the argument roles from the chatgpt_output.\n",
        "    If argument roles are provided, this will extract only those arguments.\n",
        "    Else it will extract all possible arguments from the output.\n",
        "    \"\"\"\n",
        "    arguments = {}\n",
        "    event_trigger_pattern = r\"\\bEvent Trigger:\\s*([^\\n]+)\"\n",
        "    event_trigger_match = re.search(event_trigger_pattern, chatgpt_output, re.IGNORECASE)\n",
        "    if event_trigger_match:\n",
        "        arguments[\"Event Trigger\"] = event_trigger_match.group(1).strip()\n",
        "    \n",
        "    for role in argument_roles:\n",
        "        pattern = rf\"\\b{role}:\\s*([^\\n]+)\"\n",
        "        match = re.search(pattern, chatgpt_output, re.IGNORECASE)\n",
        "        if match:\n",
        "            arguments[role] = match.group(1).strip()\n",
        "        else:\n",
        "            arguments[role] = None\n",
        "    return arguments\n",
        "\n",
        "def log_results(logs_file, input_text, event_name, event_trigger, extracted_arguments):\n",
        "    \"\"\"\n",
        "    Log the input text, event name, event trigger, and extracted arguments into logs.json.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"input_text\": input_text,\n",
        "        \"event_name\": event_name,\n",
        "        \"event_trigger\": event_trigger,\n",
        "        \"arguments\": extracted_arguments\n",
        "    }\n",
        "    with open(logs_file, 'a') as f:\n",
        "        json.dump(log_entry, f, indent=2)\n",
        "        f.write('\\n')\n",
        "\n",
        "def process_data(data_file, ontology_file, logs_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    \n",
        "    with open(data_file, newline='') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = list(reader)\n",
        "\n",
        "    for entry in data:\n",
        "        input_text = entry[\"Tweet\"]\n",
        "        event_name = entry[\"Event\"]\n",
        "        argument_roles = [\"Trigger Word\"]\n",
        "        example_sentences = {\"Trigger Word\": entry[\"Trigger Word\"].split('|') if entry[\"Trigger Word\"] else []}\n",
        "        \n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "        output_text = call_chatgpt(prompt)\n",
        "        extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "        event_trigger = extracted_arguments.pop(\"Event Trigger\", None)\n",
        "        \n",
        "        log_results(logs_file, input_text, event_name, event_trigger, extracted_arguments)\n",
        "\n",
        "# Example usage for in_context.csv:\n",
        "ontology_file = \"ontology.json\"\n",
        "logs_file = \"logs.json\"\n",
        "in_context_file = \"in_context.csv\"\n",
        "process_data(in_context_file, ontology_file, logs_file)\n",
        "\n",
        "# Use the best prompt on eval_data.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Tweet'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_data-annotated.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43montology_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpred.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[69], line 121\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_file, ontology_file, logs_file)\u001b[0m\n\u001b[1;32m    118\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(reader)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 121\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43mentry\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTweet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    122\u001b[0m     event_name \u001b[38;5;241m=\u001b[39m entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    123\u001b[0m     argument_roles \u001b[38;5;241m=\u001b[39m [role[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument_role\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m role \u001b[38;5;129;01min\u001b[39;00m ontology \u001b[38;5;28;01mif\u001b[39;00m role[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m event_name]\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Tweet'"
          ]
        }
      ],
      "source": [
        "process_data(\"eval_data-annotated.json\", ontology_file, \"pred.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "#instead of using the in_context.csv file, we are using in_context-annotated.json file. However, we do not add the annotated argument roles of the example sentences\n",
        "\n",
        "import json\n",
        "import re\n",
        "import openai\n",
        "\n",
        "# Set up the OpenAI API key\n",
        "openai.api_key = \"insert-key-here\"\n",
        "api_key = openai.api_key\n",
        "\n",
        "def load_ontology(file_name):\n",
        "    \"\"\"\n",
        "    Load the ontology from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        ontology = json.load(f)\n",
        "    return ontology\n",
        "\n",
        "def merge_example_sentences(event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Merge example sentences from the ontology with the input example sentences.\n",
        "    \"\"\"\n",
        "    for role in argument_roles:\n",
        "        for entry in ontology:\n",
        "            if entry[\"event_name\"] == event_name and entry[\"argument_role\"] == role:\n",
        "                ontology_examples = entry.get(\"example_sentence\", [])\n",
        "                if role in example_sentences:\n",
        "                    example_sentences[role].extend(ontology_examples)\n",
        "                else:\n",
        "                    example_sentences[role] = ontology_examples\n",
        "    return example_sentences\n",
        "\n",
        "def generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "    \n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "    \n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event name that is found in the sentence, each argument role followed by the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Name: <event name>\\n\"\n",
        "        \"\\nRole1: Extracted text\\n\"\n",
        "        \"Role2: Extracted text\\n\"\n",
        "        \"...\\n\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "\n",
        "\n",
        "def log_results(logs_file, input_text, prompt, output_text, extracted_arguments):\n",
        "    \"\"\"\n",
        "    Log the input text, prompt, output text, and extracted arguments into logs.json.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"input_text\": input_text,\n",
        "        \"prompt\": prompt,\n",
        "        \"output_text\": output_text,\n",
        "        \"extracted_arguments\": extracted_arguments\n",
        "    }\n",
        "    with open(logs_file, 'a') as f:\n",
        "        json.dump(log_entry, f)\n",
        "        f.write('\\n')\n",
        "\n",
        "def process_data(data_file, ontology_file, logs_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    \n",
        "    with open(data_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        \n",
        "    for entry in data:\n",
        "        input_text = entry[\"input_text\"]\n",
        "        event_name = entry[\"event_name\"]\n",
        "        argument_roles = entry[\"arguments\"].keys()\n",
        "        example_sentences = entry.get(\"example_sentence\", {})\n",
        "        \n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "        output_text = call_chatgpt(prompt)\n",
        "        extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "        \n",
        "        log_results(logs_file, input_text, prompt, output_text, extracted_arguments)\n",
        "\n",
        "# Example usage for in_context.json:\n",
        "ontology_file = \"ontology.json\"\n",
        "logs_file = \"logs.json\"\n",
        "process_data(\"in_context-annotated.json\", ontology_file, logs_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import csv\n",
        "import openai\n",
        "\n",
        "# Set up the OpenAI API key\n",
        "openai.api_key = \"insert-key-here\"\n",
        "api_key = openai.api_key\n",
        "\n",
        "def load_ontology(file_name):\n",
        "    \"\"\"\n",
        "    Load the ontology from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        ontology = json.load(f)\n",
        "    return ontology\n",
        "\n",
        "def merge_example_sentences(event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Merge example sentences from the ontology with the input example sentences.\n",
        "    \"\"\"\n",
        "    for role in argument_roles:\n",
        "        for entry in ontology:\n",
        "            if entry[\"event_name\"] == event_name and entry[\"argument_role\"] == role:\n",
        "                ontology_examples = entry.get(\"example_sentence\", [])\n",
        "                if role in example_sentences:\n",
        "                    example_sentences[role].extend(ontology_examples)\n",
        "                else:\n",
        "                    example_sentences[role] = ontology_examples\n",
        "    return example_sentences\n",
        "\n",
        "def generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def call_chatgpt(prompt):\n",
        "    \"\"\"\n",
        "    Call ChatGPT API with the generated prompt and return the response.\n",
        "    \"\"\"\n",
        "    response = openai.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def argument_extractor(chatgpt_output, argument_roles):\n",
        "    \"\"\"\n",
        "    Extract arguments corresponding to the argument roles from the chatgpt_output.\n",
        "    \"\"\"\n",
        "    arguments = {}\n",
        "    event_trigger_pattern = r\"\\bEvent Trigger:\\s*([^\\n]+)\"\n",
        "    event_trigger_match = re.search(event_trigger_pattern, chatgpt_output, re.IGNORECASE)\n",
        "    if event_trigger_match:\n",
        "        arguments[\"Event Trigger\"] = event_trigger_match.group(1).strip()\n",
        "    \n",
        "    for role in argument_roles:\n",
        "        pattern = rf\"\\b{role}:\\s*([^\\n]+)\"\n",
        "        match = re.search(pattern, chatgpt_output, re.IGNORECASE)\n",
        "        if match:\n",
        "            arguments[role] = match.group(1).strip()\n",
        "    \n",
        "    return arguments\n",
        "\n",
        "def log_results(logs_file, input_text, prompt, output_text, extracted_arguments):\n",
        "    \"\"\"\n",
        "    Log the input text, prompt, output text, and extracted arguments into logs.json.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"input_text\": input_text,\n",
        "        \"prompt\": prompt,\n",
        "        \"output_text\": output_text,\n",
        "        \"extracted_arguments\": extracted_arguments\n",
        "    }\n",
        "    with open(logs_file, 'a') as f:\n",
        "        json.dump(log_entry, f, indent=2)\n",
        "        f.write('\\n')\n",
        "\n",
        "def process_data(data_file, ontology_file, logs_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    \n",
        "    with open(data_file, newline='') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = list(reader)\n",
        "\n",
        "    for entry in data:\n",
        "        input_text = entry[\"Tweet\"]\n",
        "        event_name = entry[\"Event\"]\n",
        "        argument_roles = [role[\"argument_role\"] for role in ontology if role[\"event_name\"] == event_name]\n",
        "        example_sentences = {role: entry[\"Trigger Word\"].split('|') if entry[\"Trigger Word\"] else [] for role in argument_roles}\n",
        "        \n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "        output_text = call_chatgpt(prompt)\n",
        "        extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "        event_trigger = extracted_arguments.pop(\"Event Trigger\", None)\n",
        "        \n",
        "        log_results(logs_file, input_text, prompt, output_text, extracted_arguments)\n",
        "\n",
        "def process_eval_data(data_file, ontology_file, output_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    \n",
        "    with open(data_file, newline='') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = list(reader)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for entry in data:\n",
        "        input_text = entry[\"Tweet\"]\n",
        "        event_name = entry[\"Event\"]\n",
        "        argument_roles = [role[\"argument_role\"] for role in ontology if role[\"event_name\"] == event_name]\n",
        "        example_sentences = {role: entry[\"Trigger Word\"].split('|') if entry[\"Trigger Word\"] else [] for role in argument_roles}\n",
        "        \n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "        output_text = call_chatgpt(prompt)\n",
        "        extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "        event_trigger = extracted_arguments.pop(\"Event Trigger\", None)\n",
        "        \n",
        "        result = {\n",
        "            \"input_text\": input_text,\n",
        "            \"prompt\": prompt,\n",
        "            \"output_text\": output_text,\n",
        "            \"extracted_arguments\": extracted_arguments\n",
        "        }\n",
        "        results.append(result)\n",
        "    \n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "# Example usage for in_context.csv:\n",
        "ontology_file = \"ontology.json\"\n",
        "logs_file = \"logs.json\"\n",
        "in_context_file = \"in_context.csv\"\n",
        "process_data(in_context_file, ontology_file, logs_file)\n",
        "\n",
        "# Use the best prompt on eval_data.csv to create pred.json\n",
        "eval_data_file = \"eval_data.csv\"\n",
        "pred_output_file = \"pred.json\"\n",
        "process_eval_data(eval_data_file, ontology_file, pred_output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "#breaking chatgpt\n",
        "def generate_prompt_1(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence. Note that some roles might not exist and some might be wrongly labeled:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import csv\n",
        "import openai\n",
        "\n",
        "# Set up the OpenAI API key\n",
        "openai.api_key = \"insert-key-here\"\n",
        "api_key = openai.api_key\n",
        "\n",
        "def load_ontology(file_name):\n",
        "    \"\"\"\n",
        "    Load the ontology from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        ontology = json.load(f)\n",
        "    return ontology\n",
        "\n",
        "def merge_example_sentences(event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Merge example sentences from the ontology with the input example sentences.\n",
        "    \"\"\"\n",
        "    for role in argument_roles:\n",
        "        for entry in ontology:\n",
        "            if entry[\"event_name\"] == event_name and entry[\"argument_role\"] == role:\n",
        "                ontology_examples = entry.get(\"example_sentence\", [])\n",
        "                if role in example_sentences:\n",
        "                    example_sentences[role].extend(ontology_examples)\n",
        "                else:\n",
        "                    example_sentences[role] = ontology_examples\n",
        "    return example_sentences\n",
        "\n",
        "\n",
        "def call_chatgpt(prompt):\n",
        "    \"\"\"\n",
        "    Call ChatGPT API with the generated prompt and return the response.\n",
        "    \"\"\"\n",
        "    response = openai.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def argument_extractor(chatgpt_output, argument_roles):\n",
        "    \"\"\"\n",
        "    Extract arguments corresponding to the argument roles from the chatgpt_output.\n",
        "    \"\"\"\n",
        "    arguments = {}\n",
        "    event_trigger_pattern = r\"\\bEvent Trigger:\\s*([^\\n]+)\"\n",
        "    event_trigger_match = re.search(event_trigger_pattern, chatgpt_output, re.IGNORECASE)\n",
        "    if event_trigger_match:\n",
        "        arguments[\"Event Trigger\"] = event_trigger_match.group(1).strip()\n",
        "    \n",
        "    for role in argument_roles:\n",
        "        pattern = rf\"\\b{role}:\\s*([^\\n]+)\"\n",
        "        match = re.search(pattern, chatgpt_output, re.IGNORECASE)\n",
        "        if match:\n",
        "            arguments[role] = match.group(1).strip()\n",
        "    \n",
        "    return arguments\n",
        "\n",
        "def log_results(logs_file, input_text, prompt, output_text, extracted_arguments):\n",
        "    \"\"\"\n",
        "    Log the input text, prompt, output text, and extracted arguments into logs.json.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"input_text\": input_text,\n",
        "        \"prompt\": prompt,\n",
        "        \"output_text\": output_text,\n",
        "        \"extracted_arguments\": extracted_arguments\n",
        "    }\n",
        "    with open(logs_file, 'a') as f:\n",
        "        json.dump(log_entry, f, indent=2)\n",
        "        f.write('\\n')\n",
        "\n",
        "def process_data(data_file, ontology_file, logs_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    \n",
        "    with open(data_file, newline='') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = list(reader)\n",
        "\n",
        "    for entry in data:\n",
        "        input_text = entry[\"Tweet\"]\n",
        "        event_name = entry[\"Event\"]\n",
        "        argument_roles = [role[\"argument_role\"] for role in ontology if role[\"event_name\"] == event_name]\n",
        "        example_sentences = {role: entry[\"Trigger Word\"].split('|') if entry[\"Trigger Word\"] else [] for role in argument_roles}\n",
        "        \n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "        output_text = call_chatgpt(prompt)\n",
        "        extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "        event_trigger = extracted_arguments.pop(\"Event Trigger\", None)\n",
        "        \n",
        "        log_results(logs_file, input_text, prompt, output_text, extracted_arguments)\n",
        "\n",
        "def process_eval_data(data_file, ontology_file, output_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    \n",
        "    with open(data_file, newline='') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        data = list(reader)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for entry in data:\n",
        "        input_text = entry[\"Tweet\"]\n",
        "        event_name = entry[\"Event\"]\n",
        "        argument_roles = [role[\"argument_role\"] for role in ontology if role[\"event_name\"] == event_name]\n",
        "        example_sentences = {role: entry[\"Trigger Word\"].split('|') if entry[\"Trigger Word\"] else [] for role in argument_roles}\n",
        "        \n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "        output_text = call_chatgpt(prompt)\n",
        "        extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "        event_trigger = extracted_arguments.pop(\"Event Trigger\", None)\n",
        "        \n",
        "        result = {\n",
        "            \"input_text\": input_text,\n",
        "            \"prompt\": prompt,\n",
        "            \"output_text\": output_text,\n",
        "            \"extracted_arguments\": extracted_arguments\n",
        "        }\n",
        "        results.append(result)\n",
        "    \n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "# Example usage for in_context.csv:\n",
        "ontology_file = \"ontology.json\"\n",
        "logs_file = \"logs2.json\"\n",
        "in_context_file = \"in_context.csv\"\n",
        "process_data(in_context_file, ontology_file, logs_file)\n",
        "\n",
        "# Use the best prompt on eval_data.csv to create pred.json\n",
        "eval_data_file = \"eval_data.csv\"\n",
        "pred_output_file = \"pred2.json\"\n",
        "process_eval_data(eval_data_file, ontology_file, pred_output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_2(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. However, make sure to only use lowercase letters for the roles, \"\n",
        "        f\"and if any role is a duplicate, provide both instances but only if they are different in wording.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence. Note that some roles might not exist and some might be wrongly labeled:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role.lower()} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case, but roles in lowercase. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"role1: <extracted text>\\n\"\n",
        "        \"role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_3(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Note that you should ignore the examples if they conflict with your understanding.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference, but ignore it if you think it conflicts with your understanding:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_4(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Remember to consider all details, no matter how redundant they may seem.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence. Some information might be repeated or redundant:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference, which might contain redundant information:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_5(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Use bullet points, numbers, and roman numerals interchangeably.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for i, role in enumerate(argument_roles):\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        if i % 3 == 0:\n",
        "            prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "        elif i % 3 == 1:\n",
        "            prompt += f\"{i + 1}. {role} (Examples: {example_list})\\n\"\n",
        "        else:\n",
        "            prompt += f\"{i + 1}. {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Format your response using bullet points, numbers, and roman numerals interchangeably as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"1. Role1: <extracted text>\\n\"\n",
        "        \"ii. Role2: <extracted text>\\n\"\n",
        "        \"- Role3: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_6(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Some roles might be related to different events.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Note that some roles might be related to different events. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference, which might contain roles from different events:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_7(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Use case-insensitive extraction but maintain the original case. Also, provide a summary of the sentence.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list}, irrelevant example)\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Use case-insensitive extraction but maintain the original case. Provide a summary of the sentence as well. \"\n",
        "        \"Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text>\\n\"\n",
        "        \"Role2: <extracted text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Summary: <summary>\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_8(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Use numbers and words interchangeably for roles, and mix roles randomly.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence. Ensure to include any additional details you find important:\\n\"\n",
        "    )\n",
        "\n",
        "    for i, role in enumerate(argument_roles):\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        if i % 2 == 0:\n",
        "            prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "        else:\n",
        "            prompt += f\"- Role {i + 1} (Examples: {example_list}, unrelated example)\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Use numbers and words interchangeably for roles and mix them randomly. Include any additional details you find important. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role 1: <extracted text>\\n\"\n",
        "        \"Role2: <unrelated text>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_9(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Note that some examples might be unrelated, and you should include all examples \"\n",
        "        f\"even if they are contradictory.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence, and ensure to also extract any non-existing arguments:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list}; random example; unrelated example; contradictory example)\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Some examples might be unrelated, and you should also consider extracting non-existing arguments. \"\n",
        "        \"Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text or 'not present'>\\n\"\n",
        "        \"Role2: <extracted text or 'not present'>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_prompt_10(input_text, event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Generate a prompt for ChatGPT to extract arguments from the input text, including the entire ontology.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        f\"You are an advanced information extraction system. Your task is to identify and extract specific arguments \"\n",
        "        f\"related to a specified event in a given sentence. The event, trigger word, and argument roles are provided below, along with examples \"\n",
        "        f\"to guide you in accurately extracting the relevant information. Note that some roles may have dual meanings, and you should account for both. \"\n",
        "        f\"However, ensure you avoid any ambiguity in your responses. Ensure the dual meanings are both considered but not in a way that confuses the output.\\n\\n\"\n",
        "        f\"Event: '{event_name}'\\n\"\n",
        "        f\"Sentence: '{input_text}'\\n\\n\"\n",
        "        f\"Please extract the event trigger and the following arguments from the sentence, but ensure no event trigger is extracted if none exists:\\n\"\n",
        "    )\n",
        "\n",
        "    for role in argument_roles:\n",
        "        examples = example_sentences.get(role, [])\n",
        "        example_list = '; '.join(examples)\n",
        "        prompt += f\"- {role} (Examples: {example_list})\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        \"\\nYour response should list the event trigger followed by each argument role and the exact extracted text from the sentence, \"\n",
        "        \"maintaining the original wording and case. Some roles may have dual meanings, and you should account for both, but without causing confusion. \"\n",
        "        \"If a role is not present, indicate this explicitly. Format your response as shown below:\\n\"\n",
        "        \"\\nEvent Trigger: <event trigger>\\n\"\n",
        "        \"Role1: <extracted text or 'not present'>\\n\"\n",
        "        \"Role2: <extracted text or 'not present'>\\n\"\n",
        "        \"...\\n\"\n",
        "        \"Here is the ontology for reference:\\n\"\n",
        "    )\n",
        "\n",
        "    # Adding the entire ontology as context\n",
        "    ontology_context = json.dumps(ontology, indent=2)\n",
        "    prompt += f\"\\nOntology:\\n{ontology_context}\\n\"\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_ontology(file_name):\n",
        "    \"\"\"\n",
        "    Load the ontology from a JSON file.\n",
        "    \"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        ontology = json.load(f)\n",
        "    return ontology\n",
        "\n",
        "def merge_example_sentences(event_name, argument_roles, example_sentences, ontology):\n",
        "    \"\"\"\n",
        "    Merge example sentences from the ontology with the input example sentences.\n",
        "    \"\"\"\n",
        "    for role in argument_roles:\n",
        "        for entry in ontology:\n",
        "            if entry[\"event_name\"] == event_name and entry[\"argument_role\"] == role:\n",
        "                ontology_examples = entry.get(\"example_sentence\", [])\n",
        "                if role in example_sentences:\n",
        "                    example_sentences[role].extend(ontology_examples)\n",
        "                else:\n",
        "                    example_sentences[role] = ontology_examples\n",
        "    return example_sentences\n",
        "\n",
        "\n",
        "def call_chatgpt(prompt):\n",
        "    \"\"\"\n",
        "    Call ChatGPT API with the generated prompt and return the response.\n",
        "    \"\"\"\n",
        "    response = openai.completions.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def argument_extractor(chatgpt_output, argument_roles):\n",
        "    \"\"\"\n",
        "    Extract arguments corresponding to the argument roles from the chatgpt_output.\n",
        "    \"\"\"\n",
        "    arguments = {}\n",
        "    for role in argument_roles:\n",
        "        pattern = rf\"\\b{role}:\\s*([^\\n]+)\"\n",
        "        match = re.search(pattern, chatgpt_output, re.IGNORECASE)\n",
        "        if match:\n",
        "            arguments[role] = match.group(1).strip()\n",
        "        else:\n",
        "            arguments[role] = None\n",
        "    return arguments\n",
        "\n",
        "def log_results(logs_file, input_text, prompt, output_text, extracted_arguments, expected_arguments, event_name, event_trigger):\n",
        "    \"\"\"\n",
        "    Log the input text, prompt, output text, and extracted arguments into break-gpt.json.\n",
        "    \"\"\"\n",
        "    log_entry = {\n",
        "        \"input_text\": input_text,\n",
        "        \"event_name\": event_name,\n",
        "        \"event_trigger\": event_trigger,\n",
        "        \"prompt\": prompt,\n",
        "        \"output_text\": output_text,\n",
        "        \"extracted_arguments\": extracted_arguments,\n",
        "        \"expected_arguments\": expected_arguments\n",
        "    }\n",
        "    with open(logs_file, 'a') as f:\n",
        "        json.dump(log_entry, f, indent=2)\n",
        "        f.write('\\n')\n",
        "\n",
        "def process_data_with_variants(data_file, ontology_file, logs_file):\n",
        "    ontology = load_ontology(ontology_file)\n",
        "    prompt_variants = [generate_prompt_1, generate_prompt_2, generate_prompt_3, generate_prompt_4, generate_prompt_5, generate_prompt_6, generate_prompt_7, generate_prompt_8, generate_prompt_9, generate_prompt_10]\n",
        "\n",
        "    with open(data_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for entry in data:\n",
        "        input_text = entry[\"input_text\"]\n",
        "        event_name = entry[\"event_name\"]\n",
        "        event_trigger = entry[\"event_trigger\"]\n",
        "        argument_roles = entry[\"arguments\"].keys()\n",
        "        example_sentences = entry.get(\"example_sentence\", {})\n",
        "        expected_arguments = entry[\"arguments\"]\n",
        "\n",
        "        example_sentences = merge_example_sentences(event_name, argument_roles, example_sentences, ontology)\n",
        "        \n",
        "        for generate_prompt in prompt_variants:\n",
        "            prompt = generate_prompt(input_text, event_name, argument_roles, example_sentences, ontology)\n",
        "            output_text = call_chatgpt(prompt)\n",
        "            extracted_arguments = argument_extractor(output_text, argument_roles)\n",
        "            \n",
        "            if extracted_arguments != expected_arguments:\n",
        "                log_results(logs_file, input_text, prompt, output_text, extracted_arguments, expected_arguments, event_name, event_trigger)\n",
        "\n",
        "# Example usage for in_context-annotated.json:\n",
        "ontology_file = \"ontology.json\"\n",
        "logs_file = \"break-gpt.json\"\n",
        "process_data_with_variants(\"in_context-annotated.json\", ontology_file, logs_file)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
